name: AI Pipeline Failure Triage

on:
  workflow_run:
    workflows: ["ML Model CI/CT/CD Pipeline"]
    types:
      - completed

permissions:
  contents: read
  issues: write
  actions: read

jobs:
  triage-failure:
    name: AI-Powered Failure Analysis
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'failure' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Get workflow run details and extract logs
        id: workflow-info
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const path = require('path');
            const { exec } = require('child_process');
            const util = require('util');
            const execPromise = util.promisify(exec);
            
            const runId = context.payload.workflow_run.id;
            
            // Get workflow run details
            const run = await github.rest.actions.getWorkflowRun({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: runId
            });
            
            // Get all jobs for this run
            const jobs = await github.rest.actions.listJobsForWorkflowRun({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: runId,
              filter: 'latest'
            });
            
            const failedJobs = jobs.data.jobs.filter(job => job.conclusion === 'failure');
            
            let failureLogs = 'No logs available';
            let failedStepName = 'Unknown';
            
            if (failedJobs.length > 0) {
              const failedJob = failedJobs[0];
              const jobId = failedJob.id;
              
              // Find the failed step
              const failedStep = failedJob.steps.find(s => s.conclusion === 'failure');
              if (failedStep) {
                failedStepName = failedStep.name;
              }
              
              try {
                // Download logs as ZIP
                const logsUrl = await github.rest.actions.downloadJobLogsForWorkflowRun({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  job_id: jobId
                });
                
                // Fetch the ZIP file
                const response = await fetch(logsUrl.url);
                const buffer = await response.arrayBuffer();
                
                // Save ZIP file
                const zipPath = path.join(process.env.GITHUB_WORKSPACE, 'logs.zip');
                fs.writeFileSync(zipPath, Buffer.from(buffer));
                
                // Extract ZIP file
                const extractDir = path.join(process.env.GITHUB_WORKSPACE, 'logs');
                fs.mkdirSync(extractDir, { recursive: true });
                
                await execPromise(`unzip -q "${zipPath}" -d "${extractDir}"`);
                
                // Read all log files and concatenate
                const logFiles = fs.readdirSync(extractDir);
                let allLogs = [];
                
                for (const file of logFiles) {
                  const logPath = path.join(extractDir, file);
                  if (fs.statSync(logPath).isFile()) {
                    const content = fs.readFileSync(logPath, 'utf8');
                    allLogs.push(`\n=== ${file} ===\n${content}`);
                  }
                }
                
                // Combine all logs
                const fullLogs = allLogs.join('\n');
                
                // Extract error messages (Python tracebacks, error lines, etc.)
                const errorPatterns = [
                  /^.*Error:.*$/gm,
                  /^.*Exception:.*$/gm,
                  /^.*Traceback.*$/gm,
                  /^.*File ".*", line \d+.*$/gm,
                  /^.*ModuleNotFoundError.*$/gm,
                  /^.*ImportError.*$/gm,
                  /^.*FAILED.*$/gm,
                  /^.*failed.*$/gmi
                ];
                
                let relevantLogs = [];
                for (const pattern of errorPatterns) {
                  const matches = fullLogs.match(pattern);
                  if (matches) {
                    relevantLogs.push(...matches);
                  }
                }
                
                // If we found error lines, use them; otherwise use last 200 lines
                if (relevantLogs.length > 0) {
                  // Get context around errors (10 lines before and after each error)
                  const lines = fullLogs.split('\n');
                  let contextLines = new Set();
                  
                  relevantLogs.forEach(errorLine => {
                    const index = lines.indexOf(errorLine);
                    if (index !== -1) {
                      for (let i = Math.max(0, index - 10); i < Math.min(lines.length, index + 10); i++) {
                        contextLines.add(lines[i]);
                      }
                    }
                  });
                  
                  failureLogs = Array.from(contextLines).join('\n');
                } else {
                  // Fallback: last 200 lines
                  const lines = fullLogs.split('\n');
                  failureLogs = lines.slice(-200).join('\n');
                }
                
                // Limit to 8000 characters for Gemini
                if (failureLogs.length > 8000) {
                  failureLogs = failureLogs.substring(failureLogs.length - 8000);
                }
                
              } catch (error) {
                failureLogs = `Error extracting logs: ${error.message}\n\nJob details: ${JSON.stringify(failedJob, null, 2)}`;
              }
            }
            
            const failureInfo = {
              workflow_name: run.data.name,
              run_url: run.data.html_url,
              failed_job_name: failedJobs.length > 0 ? failedJobs[0].name : 'Unknown',
              failed_step: failedStepName,
              commit_message: run.data.head_commit.message,
              commit_sha: run.data.head_sha.substring(0, 7),
              branch: run.data.head_branch,
              logs: failureLogs
            };
            
            core.setOutput('failure_info', JSON.stringify(failureInfo));
            return failureInfo;

      - name: Analyze failure with Gemini AI
        id: ai-analysis
        run: |
          # Install gcloud SDK
          curl https://sdk.cloud.google.com | bash -s -- --disable-prompts
          source $HOME/google-cloud-sdk/path.bash.inc
          
          # Authenticate
          echo "${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}" | base64 -d > /tmp/gcp-key.json
          gcloud auth activate-service-account --key-file=/tmp/gcp-key.json
          gcloud config set project ${{ secrets.GCP_PROJECT_ID }}
          
          # Get access token
          ACCESS_TOKEN=$(gcloud auth print-access-token)
          
          # Parse failure info
          FAILURE_INFO='${{ steps.workflow-info.outputs.failure_info }}'
          
          # Determine failure type
          FAILED_JOB=$(echo $FAILURE_INFO | jq -r '.failed_job_name')
          FAILED_STEP=$(echo $FAILURE_INFO | jq -r '.failed_step')
          
          if [[ "$FAILED_JOB" == *"SAST"* ]] || [[ "$FAILED_JOB" == *"Bandit"* ]]; then
            FAILURE_TYPE="Security Scan (SAST)"
            PROMPT_CONTEXT="You are a DevSecOps security specialist analyzing a SAST security scan failure."
          elif [[ "$FAILED_JOB" == *"train"* ]] || [[ "$FAILED_JOB" == *"Training"* ]] || [[ "$FAILED_STEP" == *"Train"* ]]; then
            FAILURE_TYPE="Model Training/Validation"
            PROMPT_CONTEXT="You are an ML engineer analyzing a model training or validation failure."
          elif [[ "$FAILED_JOB" == *"test"* ]] || [[ "$FAILED_STEP" == *"test"* ]]; then
            FAILURE_TYPE="Unit Tests"
            PROMPT_CONTEXT="You are a Python testing expert analyzing unit test failures."
          elif [[ "$FAILED_JOB" == *"Container"* ]] || [[ "$FAILED_JOB" == *"Trivy"* ]]; then
            FAILURE_TYPE="Container Security Scan"
            PROMPT_CONTEXT="You are a DevSecOps specialist analyzing container vulnerability scan failures."
          elif [[ "$FAILED_STEP" == *"Lint"* ]] || [[ "$FAILED_STEP" == *"flake8"* ]]; then
            FAILURE_TYPE="Code Quality/Linting"
            PROMPT_CONTEXT="You are a Python code quality expert analyzing linting failures."
          else
            FAILURE_TYPE="Pipeline Failure"
            PROMPT_CONTEXT="You are a DevOps/MLOps engineer analyzing a CI/CD pipeline failure."
          fi
          
          # Build prompt
          PROMPT_TEXT="${PROMPT_CONTEXT}\n\n**Pipeline Failure Details:**\n- Workflow: $(echo $FAILURE_INFO | jq -r '.workflow_name')\n- Failed Job: $(echo $FAILURE_INFO | jq -r '.failed_job_name')\n- Failed Step: $(echo $FAILURE_INFO | jq -r '.failed_step')\n- Branch: $(echo $FAILURE_INFO | jq -r '.branch')\n- Commit: $(echo $FAILURE_INFO | jq -r '.commit_sha') - $(echo $FAILURE_INFO | jq -r '.commit_message')\n\n**Extracted Error Logs:**\n\`\`\`\n$(echo $FAILURE_INFO | jq -r '.logs')\n\`\`\`\n\n**Your Task:**\nAnalyze the ACTUAL error messages and stack traces in the logs above. Provide:\n\n1. **Root Cause** - What EXACTLY caused the failure based on the error messages?\n2. **Risk Assessment** - Is this a blocker or can it be ignored?\n3. **Fix Instructions** - Specific code changes or commands to fix this\n4. **Prevention** - How to avoid this in the future?\n\nFocus on the actual Python errors, tracebacks, and failure messages. Ignore warnings unless they're the direct cause. Be specific with file names and line numbers from the logs. Keep under 500 words."
          
          # Create JSON payload
          cat > gemini-request.json << EOF
          {
            "contents": [{
              "role": "user",
              "parts": [{
                "text": $(echo "$PROMPT_TEXT" | jq -Rs .)
              }]
            }],
            "generationConfig": {
              "temperature": 0.2,
              "maxOutputTokens": 1024,
              "topP": 0.95
            }
          }
          EOF
          
          # Call Gemini API
          ANALYSIS=$(curl -s -X POST \
            -H "Authorization: Bearer ${ACCESS_TOKEN}" \
            -H "Content-Type: application/json" \
            "https://us-central1-aiplatform.googleapis.com/v1/projects/${{ secrets.GCP_PROJECT_ID }}/locations/us-central1/publishers/google/models/gemini-2.5-flash-lite:generateContent" \
            -d @gemini-request.json | jq -r '.candidates[0].content.parts[0].text // "âŒ Gemini API call failed"')
          
          echo "$ANALYSIS" > triage-report.md
          echo "ANALYSIS<<EOF" >> $GITHUB_OUTPUT
          echo "$ANALYSIS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "FAILURE_TYPE=$FAILURE_TYPE" >> $GITHUB_OUTPUT

      - name: Create GitHub Issue with Triage Report
        uses: actions/github-script@v7
        env:
          ANALYSIS_CONTENT: ${{ steps.ai-analysis.outputs.ANALYSIS }}
          FAILURE_TYPE: ${{ steps.ai-analysis.outputs.FAILURE_TYPE }}
          FAILURE_INFO: ${{ steps.workflow-info.outputs.failure_info }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const analysis = process.env.ANALYSIS_CONTENT;
            const failureType = process.env.FAILURE_TYPE;
            const failureInfo = JSON.parse(process.env.FAILURE_INFO);
            
            let severityLabel = 'pipeline-failure';
            if (failureType.includes('Security')) {
              severityLabel = 'security-issue';
            } else if (failureType.includes('Training')) {
              severityLabel = 'ml-model-issue';
            }
            
            const issueBody = [
              `## ðŸ”´ Pipeline Failure: ${failureInfo.failed_job_name}`,
              '',
              `**Failure Type:** ${failureType}`,
              `**Failed Step:** ${failureInfo.failed_step}`,
              `**Branch:** \`${failureInfo.branch}\``,
              `**Commit:** ${failureInfo.commit_sha} - ${failureInfo.commit_message}`,
              `**Workflow Run:** ${failureInfo.run_url}`,
              '',
              '---',
              '',
              '## ðŸ¤– AI-Generated Triage Analysis',
              '',
              analysis,
              '',
              '---',
              '',
              '## ðŸ“‹ Quick Actions',
              '',
              '- [ ] Review the AI analysis above',
              '- [ ] Apply the suggested fix',
              '- [ ] Test locally before pushing',
              '- [ ] Update tests/configs if needed',
              '',
              '---',
              '',
              '<details>',
              '<summary>ðŸ“Š View Extracted Error Logs</summary>',
              '',
              '```',
              failureInfo.logs,
              '```',
              '',
              '</details>',
              '',
              '---',
              '',
              '**Triage Engine:** Google Gemini 2.5 Flash Lite',
              `**Auto-generated:** ${new Date().toISOString()}`
            ].join('\n');
            
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `[PIPELINE FAILURE] ${failureType} - ${failureInfo.commit_sha}`,
              body: issueBody,
              labels: ['pipeline-failure', 'ai-triage', severityLabel]
            });

      - name: Upload triage report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ai-triage-report
          path: triage-report.md